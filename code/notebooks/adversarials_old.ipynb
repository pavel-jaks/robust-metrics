{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Metric, WassersteinApproximation, StructuralDissimilarity, L2Metric, LinfMetric, LpMetric, NoiseToPeakSignalRatio\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'metrics'"
     ]
    }
   ],
   "source": [
    "from metrics import Metric, WassersteinApproximation, StructuralDissimilarity, L2Metric, LinfMetric, LpMetric, NoiseToPeakSignalRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models\\\\model_v1.model')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        'mnist',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.ToTensor()\n",
    "    ),\n",
    "    batch_size=50,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benign_examples(model, dataloader, count):\n",
    "    counter = 0\n",
    "    benign_examples = torch.zeros(count, 1, dataloader.dataset[0][0].shape[1], dataloader.dataset[0][0].shape[2])\n",
    "    benign_labels = torch.zeros(count)\n",
    "    for examples, labels in dataloader:\n",
    "        preds = model(examples)\n",
    "        match = (torch.argmax(preds, dim=1) == labels)\n",
    "        for idx, foo in enumerate(match):\n",
    "            if foo:\n",
    "                benign_examples[counter] = examples[idx]\n",
    "                benign_labels[counter] = labels[idx]\n",
    "                counter += 1\n",
    "            if counter >= count:\n",
    "                break\n",
    "        if counter >= count:\n",
    "            break\n",
    "    return benign_examples, benign_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 20\n",
    "\n",
    "benign, labels = get_benign_examples(model, train_loader, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_batch(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, c_lambda: float, metric: Metric, special_init = False) -> torch.Tensor:\n",
    "    if special_init:\n",
    "        adversarial_examples = benign_examples\n",
    "    else:\n",
    "        adversarial_examples = 0.5 * torch.ones(benign_examples.shape) + 0.3 * (2 * torch.rand(benign_examples.shape) - 1)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    step_size = 1e-2\n",
    "    for i in range(100):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad is not None:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        benign_examples.requires_grad = True\n",
    "        if benign_examples.grad is not None:\n",
    "            benign_examples.grad.zero_()\n",
    "        metrics = metric(benign_examples, adversarial_examples)\n",
    "        # if (i + 1) % 10 == 0:\n",
    "        #     print(metrics)\n",
    "        loss = metrics.sum() - c_lambda * loss_fn(model(adversarial_examples), torch.tensor(labels, dtype=torch.long))\n",
    "        \n",
    "        loss.backward()\n",
    "        # if (i + 1) % 10 == 0:\n",
    "        #     print(adversarial_examples.grad)\n",
    "        adversarial_examples = (adversarial_examples - step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)).detach()\n",
    "        # ex = adversarial_examples[0].detach().reshape(28, 28)\n",
    "        # if (i + 1) % 10 == 0:   \n",
    "        #     plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "        #     plt.show()\n",
    "    return adversarial_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [1000, 100, 10, 1, 0.1, 0.01, 0.001]\n",
    "\n",
    "metrics = []\n",
    "\n",
    "metrics.append(\n",
    "    {\n",
    "        'metric': LpMetric(p=1),\n",
    "        'name': 'L1'\n",
    "    }\n",
    ")\n",
    "\n",
    "metrics.append(\n",
    "    {\n",
    "        'metric': L2Metric(),\n",
    "        'name': 'L2'\n",
    "    }\n",
    ")\n",
    "metrics.append(\n",
    "    {\n",
    "        'metric': LinfMetric(),\n",
    "        'name': 'Linf'\n",
    "    }\n",
    ")\n",
    "\n",
    "# DSSIM\n",
    "for window_size in [5, 13, 21, 28]:\n",
    "    metrics.append(\n",
    "        {\n",
    "            'metric': StructuralDissimilarity(window_size=window_size),\n",
    "            'name': f'DSSIM_ws{window_size}'\n",
    "        }\n",
    "    )\n",
    "\n",
    "metrics.append(\n",
    "    {\n",
    "        'metric': NoiseToPeakSignalRatio(),\n",
    "        'name': 'NPSR'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = L2Metric()\n",
    "\n",
    "for metric in metrics:\n",
    "    for lambd in lambdas:\n",
    "        adv = cw_batch(model, benign, labels, lambd, metric['metric'])\n",
    "        metric['adv'] = adv\n",
    "        metric['success'] = torch.argmax(model(adv), dim=1) != labels\n",
    "        metric['dist'] = metric['metric'](benign, adv)\n",
    "        metric['L2_dist'] = l2(benign, adv)\n",
    "        for i, example in enumerate(adv):\n",
    "            ex = example.detach().reshape(28, 28)\n",
    "            plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.savefig(\n",
    "                f\"adversarials\\\\cw\\\\{metric['name']}_lambda{lambd}_{'adv' if metric['success'][i] else 'ben'}_dist{metric['dist'][i]}_d2{metric['L2_dist'][i]}_{i+1}.png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0)\n",
    "        print(f'___DONE lambda = {lambd}')\n",
    "    print(f\"DONE metric {metric['name']}\")\n",
    "\n",
    "for i, ben in enumerate(benign):\n",
    "    ex = ben.detach().reshape(28, 28)\n",
    "    plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        f\"adversarials\\\\cw\\\\benign_{i+1}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adversarials\\\\cw\\\\results.json', 'w') as f:\n",
    "    metrics_to_json = []\n",
    "    for metric in metrics:\n",
    "        metrics_to_json.append(\n",
    "            {\n",
    "                'metric_name': metric['name'],\n",
    "                'success': metric['success'].tolist(),\n",
    "                'dist': metric['dist'].tolist(),\n",
    "                'L2_dist': metric['L2_dist'].tolist(),\n",
    "            }\n",
    "        )\n",
    "    json.dump(metrics_to_json, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lambd in lambdas:\n",
    "    metric = {'metric': LinfMetric()}\n",
    "    metric['name'] = 'Linf_special'\n",
    "    adv = cw_batch(model, benign, labels, lambd, metric['metric'], special_init=True)\n",
    "    metric['adv'] = adv\n",
    "    metric['success'] = torch.argmax(model(adv), dim=1) != labels\n",
    "    metric['dist'] = metric['metric'](benign, adv)\n",
    "    metric['L2_dist'] = l2(benign, adv)\n",
    "    for i, example in enumerate(adv):\n",
    "        ex = example.detach().reshape(28, 28)\n",
    "        plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(\n",
    "            f\"adversarials\\\\cw\\\\{metric['name']}_lambda{lambd}_{'adv' if metric['success'][i] else 'ben'}_dist{metric['dist'][i]}_d2{metric['L2_dist'][i]}_{i+1}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "            pad_inches=0)\n",
    "    print(f'___DONE lambda = {lambd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lambd in lambdas:\n",
    "    metric = {'metric': NoiseToPeakSignalRatio()}\n",
    "    metric['name'] = 'NPSR'\n",
    "    adv = cw_batch(model, benign, labels, lambd, metric['metric'], special_init=True)\n",
    "    metric['adv'] = adv\n",
    "    metric['success'] = torch.argmax(model(adv), dim=1) != labels\n",
    "    metric['dist'] = metric['metric'](benign, adv)\n",
    "    metric['L2_dist'] = l2(benign, adv)\n",
    "    for i, example in enumerate(adv):\n",
    "        ex = example.detach().reshape(28, 28)\n",
    "        plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(\n",
    "            f\"adversarials\\\\cw\\\\{metric['name']}_lambda{lambd}_{'adv' if metric['success'][i] else 'ben'}_dist{metric['dist'][i]}_d2{metric['L2_dist'][i]}_{i+1}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "            pad_inches=0)\n",
    "    print(f'___DONE lambda = {lambd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lambd in [10000, 100000]:\n",
    "    metric = {'metric': NoiseToPeakSignalRatio()}\n",
    "    metric['name'] = 'NPSR'\n",
    "    adv = cw_batch(model, benign, labels, lambd, metric['metric'], special_init=True)\n",
    "    metric['adv'] = adv\n",
    "    metric['success'] = torch.argmax(model(adv), dim=1) != labels\n",
    "    metric['dist'] = metric['metric'](benign, adv)\n",
    "    metric['L2_dist'] = l2(benign, adv)\n",
    "    for i, example in enumerate(adv):\n",
    "        ex = example.detach().reshape(28, 28)\n",
    "        plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(\n",
    "            f\"adversarials\\\\cw\\\\{metric['name']}_lambda{lambd}_{'adv' if metric['success'][i] else 'ben'}_dist{metric['dist'][i]}_d2{metric['L2_dist'][i]}_{i+1}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "            pad_inches=0)\n",
    "    print(f'___DONE lambda = {lambd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('adversarials\\\\cw\\\\results.json', 'w') as f:\n",
    "    metrics_to_json = []\n",
    "    for metric in metrics:\n",
    "        metrics_to_json.append(\n",
    "            {\n",
    "                'metric_name': metric['name'],\n",
    "                'success': metric['success'].tolist(),\n",
    "                'dist': metric['dist'].tolist(),\n",
    "                'L2_dist': metric['L2_dist'].tolist(),\n",
    "            }\n",
    "        )\n",
    "    json.dump(metrics_to_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = L2Metric()\n",
    "\n",
    "for metric in metrics:\n",
    "    for lambd in lambdas:\n",
    "        adv = cw_batch(model, benign, labels, lambd, metric['metric'])\n",
    "        metric[f'lambda{lambd}'] = {}\n",
    "        metric[f'lambda{lambd}']['success'] = (torch.argmax(model(adv), dim=1) != labels).tolist()\n",
    "        metric[f'lambda{lambd}']['dist'] = metric['metric'](benign, adv).tolist()\n",
    "        metric[f'lambda{lambd}']['L2_dist'] = l2(benign, adv).tolist()\n",
    "        print(f'___DONE lambda = {lambd}')\n",
    "    print(f\"DONE metric {metric['name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('adversarials\\\\cw\\\\results.json', 'w') as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "for file_name in os.listdir('adversarials\\\\cw'):\n",
    "    file_names.append(os.path.splitext(file_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
