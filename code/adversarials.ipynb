{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import Metric, WassersteinApproximation, StructuralDissimilarity, L2Metric, LinfNorm, LpMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models\\\\model_v1.model')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        'mnist',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.ToTensor()\n",
    "    ),\n",
    "    batch_size=50,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benign_examples(model, dataloader, count):\n",
    "    counter = 0\n",
    "    benign_examples = torch.zeros(count, 1, dataloader.dataset[0][0].shape[1], dataloader.dataset[0][0].shape[2])\n",
    "    benign_labels = torch.zeros(count)\n",
    "    for examples, labels in dataloader:\n",
    "        preds = model(examples)\n",
    "        match = (torch.argmax(preds, dim=1) == labels)\n",
    "        for idx, foo in enumerate(match):\n",
    "            if foo:\n",
    "                benign_examples[counter] = examples[idx]\n",
    "                benign_labels[counter] = labels[idx]\n",
    "                counter += 1\n",
    "            if counter >= count:\n",
    "                break\n",
    "        if counter >= count:\n",
    "            break\n",
    "    return benign_examples, benign_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 5\n",
    "\n",
    "benign, labels = get_benign_examples(model, train_loader, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_batch(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, c_lambda: float, metric: Metric, special_init = False) -> torch.Tensor:\n",
    "    if special_init:\n",
    "        adversarial_examples = benign_examples\n",
    "    else:\n",
    "        adversarial_examples = 0.5 * torch.ones(benign_examples.shape) + 0.3 * (2 * torch.rand(benign_examples.shape) - 1)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    step_size = 1e-2\n",
    "    for i in range(100):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad is not None:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        benign_examples.requires_grad = True\n",
    "        if benign_examples.grad is not None:\n",
    "            benign_examples.grad.zero_()\n",
    "        metrics = metric(benign_examples, adversarial_examples)\n",
    "        \n",
    "        loss = metrics[metrics == metrics].sum() - c_lambda * loss_fn(model(adversarial_examples), torch.tensor(labels, dtype=torch.long))\n",
    "        loss.backward()\n",
    "        adversarial_examples = (adversarial_examples - step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)).detach()\n",
    "        adversarial_examples[adversarial_examples < 0] = 0\n",
    "        adversarial_examples[adversarial_examples > 1] = 1\n",
    "        \n",
    "    return adversarial_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [1000, 100, 10, 1, 0.1, 0.01, 0.001]\n",
    "\n",
    "metrics = []\n",
    "\n",
    "metrics.append(\n",
    "    {\n",
    "        'metric': LpMetric(p=1),\n",
    "        'name': 'L1'\n",
    "    }\n",
    ")\n",
    "\n",
    "metrics.append(\n",
    "    {\n",
    "        'metric': L2Metric(),\n",
    "        'name': 'L2'\n",
    "    }\n",
    ")\n",
    "\n",
    "# DSSIM\n",
    "for window_size in [5, 13, 21, 28]:\n",
    "    metrics.append(\n",
    "        {\n",
    "            'metric': StructuralDissimilarity(window_size=window_size),\n",
    "            'name': f'DSSIM_ws{window_size}'\n",
    "        }\n",
    "    )\n",
    "\n",
    "metrics.append(\n",
    "    {\n",
    "        'metric': WassersteinApproximation(regularization=3, iterations=150),\n",
    "        'name': 'WassersteinAproximation'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stani\\AppData\\Local\\Temp\\ipykernel_18224\\2774663418.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = metrics[metrics == metrics].sum() - c_lambda * loss_fn(model(adversarial_examples), torch.tensor(labels, dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric L1\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric L2\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric DSSIM_ws5\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric DSSIM_ws13\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric DSSIM_ws21\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric DSSIM_ws28\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric WassersteinAproximation\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2 = L2Metric()\n",
    "\n",
    "for metric in metrics:\n",
    "    for lambd in lambdas:\n",
    "        adv = cw_batch(model, benign, labels, lambd, metric['metric'])\n",
    "        metric['adv'] = adv\n",
    "        metric['success'] = torch.argmax(model(adv), dim=1) != labels\n",
    "        metric['dist'] = metric['metric'](benign, adv)\n",
    "        metric['L2_dist'] = l2(benign, adv)\n",
    "        for i, example in enumerate(adv):\n",
    "            ex = example.detach().reshape(28, 28)\n",
    "            plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.savefig(\n",
    "                f\"adversarials\\\\test\\\\{metric['name']}_lambda={lambd}_{'adv' if metric['success'][i] else 'ben'}_dist={metric['dist'][i]}_d2={metric['L2_dist'][i]}_{i+1}.png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0)\n",
    "        print(f'___DONE lambda = {lambd}')\n",
    "    print(f\"DONE metric {metric['name']}\")\n",
    "\n",
    "for i, ben in enumerate(benign):\n",
    "    ex = ben.detach().reshape(28, 28)\n",
    "    plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        f\"adversarials\\\\test\\\\benign_{i+1}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adversarials\\\\test\\\\results.json', 'w') as f:\n",
    "    metrics_to_json = []\n",
    "    for metric in metrics:\n",
    "        metrics_to_json.append(\n",
    "            {\n",
    "                'metric_name': metric['name'],\n",
    "                'success': metric['success'].tolist(),\n",
    "                'dist': metric['dist'].tolist(),\n",
    "                'L2_dist': metric['L2_dist'].tolist(),\n",
    "            }\n",
    "        )\n",
    "    json.dump(metrics_to_json, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ad Hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [1000, 100, 10, 1, 0.1, 0.01, 0.001]\n",
    "batch = 5\n",
    "metrics_wass = []\n",
    "\n",
    "metrics_wass.append(\n",
    "    {\n",
    "        'metric': WassersteinApproximation(regularization=5, iterations=150),\n",
    "        'name': 'WassersteinAproximationreg=5_iter=150'\n",
    "    }\n",
    ")\n",
    "\n",
    "metrics_wass.append(\n",
    "    {\n",
    "        'metric': WassersteinApproximation(regularization=5, iterations=250),\n",
    "        'name': 'WassersteinAproximationreg=5_iter=250'\n",
    "    }\n",
    ")\n",
    "\n",
    "metrics_wass.append(\n",
    "    {\n",
    "        'metric': WassersteinApproximation(regularization=3, iterations=250),\n",
    "        'name': 'WassersteinAproximationreg=3_iter=250'\n",
    "    }\n",
    ")\n",
    "\n",
    "metrics_wass.append(\n",
    "    {\n",
    "        'metric': WassersteinApproximation(regularization=3, iterations=500),\n",
    "        'name': 'WassersteinAproximationreg=3_iter=500'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stani\\AppData\\Local\\Temp\\ipykernel_18224\\2774663418.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = metrics[metrics == metrics].sum() - c_lambda * loss_fn(model(adversarial_examples), torch.tensor(labels, dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric WassersteinAproximationreg=5_iter=150\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric WassersteinAproximationreg=5_iter=250\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric WassersteinAproximationreg=3_iter=250\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric WassersteinAproximationreg=3_iter=500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2 = L2Metric()\n",
    "\n",
    "for metric in metrics_wass:\n",
    "    for lambd in lambdas:\n",
    "        adv = cw_batch(model, benign, labels, lambd, metric['metric'])\n",
    "        metric['adv'] = adv\n",
    "        metric['success'] = torch.argmax(model(adv), dim=1) != labels\n",
    "        metric['dist'] = metric['metric'](benign, adv)\n",
    "        metric['L2_dist'] = l2(benign, adv)\n",
    "        for i, example in enumerate(adv):\n",
    "            ex = example.detach().reshape(28, 28)\n",
    "            plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.savefig(\n",
    "                f\"adversarials\\\\test\\\\{metric['name']}_lambda={lambd}_{'adv' if metric['success'][i] else 'ben'}_dist={metric['dist'][i]}_d2={metric['L2_dist'][i]}_{i+1}.png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0)\n",
    "        print(f'___DONE lambda = {lambd}')\n",
    "    print(f\"DONE metric {metric['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [1e4, 1e5, 1e6, 1e7]\n",
    "batch = 5\n",
    "metrics_wass = []\n",
    "\n",
    "metrics_wass.append(\n",
    "    {\n",
    "        'metric': WassersteinApproximation(regularization=3, iterations=150),\n",
    "        'name': 'WassersteinAproximation'\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
