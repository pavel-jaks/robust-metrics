{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import Metric, WassersteinApproximation, StructuralDissimilarity, L2Metric, LinfMetric, LpMetric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models\\\\model_v1.model')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        'mnist',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.ToTensor()\n",
    "    ),\n",
    "    batch_size=50,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benign_examples(model, dataloader, count):\n",
    "    counter = 0\n",
    "    benign_examples = torch.zeros(count, 1, dataloader.dataset[0][0].shape[1], dataloader.dataset[0][0].shape[2])\n",
    "    benign_labels = torch.zeros(count)\n",
    "    for examples, labels in dataloader:\n",
    "        preds = model(examples)\n",
    "        match = (torch.argmax(preds, dim=1) == labels)\n",
    "        for idx, foo in enumerate(match):\n",
    "            if foo:\n",
    "                benign_examples[counter] = examples[idx]\n",
    "                benign_labels[counter] = labels[idx]\n",
    "                counter += 1\n",
    "            if counter >= count:\n",
    "                break\n",
    "        if counter >= count:\n",
    "            break\n",
    "    return benign_examples, benign_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 20\n",
    "\n",
    "benign, labels = get_benign_examples(model, train_loader, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_batch(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, c_lambda: float, metric: Metric) -> torch.Tensor:\n",
    "    adversarial_examples = 0.5 * torch.ones(benign_examples.shape) + 0.3 * (2 * torch.rand(benign_examples.shape) - 1)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    step_size = 1e-2\n",
    "    for i in range(100):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad is not None:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        benign_examples.requires_grad = True\n",
    "        if benign_examples.grad is not None:\n",
    "            benign_examples.grad.zero_()\n",
    "        metrics = metric(benign_examples, adversarial_examples)\n",
    "        # if (i + 1) % 10 == 0:\n",
    "        #     print(metrics)\n",
    "        loss = metrics.sum() - c_lambda * loss_fn(model(adversarial_examples), torch.tensor(labels, dtype=torch.long))\n",
    "        \n",
    "        loss.backward()\n",
    "        # if (i + 1) % 10 == 0:\n",
    "        #     print(adversarial_examples.grad)\n",
    "        adversarial_examples = (adversarial_examples - step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)).detach()\n",
    "        # ex = adversarial_examples[0].detach().reshape(28, 28)\n",
    "        # if (i + 1) % 10 == 0:   \n",
    "        #     plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "        #     plt.show()\n",
    "    return adversarial_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [1000, 100, 10, 1, 0.1, 0.01, 0.001]\n",
    "\n",
    "metrics = []\n",
    "\n",
    "metrics.append(\n",
    "    {\n",
    "        'metric': LpMetric(p=1),\n",
    "        'name': 'L1'\n",
    "    }\n",
    ")\n",
    "\n",
    "metrics.append(\n",
    "    {\n",
    "        'metric': L2Metric(),\n",
    "        'name': 'L2'\n",
    "    }\n",
    ")\n",
    "metrics.append(\n",
    "    {\n",
    "        'metric': LinfMetric(),\n",
    "        'name': 'Linf'\n",
    "    }\n",
    ")\n",
    "\n",
    "# DSSIM\n",
    "for window_size in [5, 13, 21, 28]:\n",
    "    metrics.append(\n",
    "        {\n",
    "            'metric': StructuralDissimilarity(window_size=window_size),\n",
    "            'name': f'DSSIM_ws{window_size}'\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stani\\AppData\\Local\\Temp\\ipykernel_19000\\3669848702.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = metrics.sum() - c_lambda * loss_fn(model(adversarial_examples), torch.tensor(labels, dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric L1\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric L2\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric Linf\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric DSSIM_ws5\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric DSSIM_ws13\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric DSSIM_ws21\n",
      "___DONE lambda = 1000\n",
      "___DONE lambda = 100\n",
      "___DONE lambda = 10\n",
      "___DONE lambda = 1\n",
      "___DONE lambda = 0.1\n",
      "___DONE lambda = 0.01\n",
      "___DONE lambda = 0.001\n",
      "DONE metric DSSIM_ws28\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2 = L2Metric()\n",
    "\n",
    "for metric in metrics:\n",
    "    for lambd in lambdas:\n",
    "        adv = cw_batch(model, benign, labels, lambd, metric['metric'])\n",
    "        metric['adv'] = adv\n",
    "        metric['success'] = torch.argmax(model(adv), dim=1) != labels\n",
    "        metric['dist'] = metric['metric'](benign, adv)\n",
    "        metric['L2_dist'] = l2(benign, adv)\n",
    "        for i, example in enumerate(adv):\n",
    "            ex = example.detach().reshape(28, 28)\n",
    "            plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.savefig(\n",
    "                f\"adversarials\\\\cw\\\\{metric['name']}_lambda{lambd}_{'adv' if metric['success'][i] else 'ben'}_dist{metric['dist'][i]}_d2{metric['L2_dist'][i]}_{i+1}.png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0)\n",
    "        print(f'___DONE lambda = {lambd}')\n",
    "    print(f\"DONE metric {metric['name']}\")\n",
    "\n",
    "for i, ben in enumerate(benign):\n",
    "    ex = ben.detach().reshape(28, 28)\n",
    "    plt.imshow(ex, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\n",
    "        f\"adversarials\\\\cw\\\\benign_{i+1}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adversarials\\\\cw\\\\results.json', 'w') as f:\n",
    "    metrics_to_json = []\n",
    "    for metric in metrics:\n",
    "        metrics_to_json.append(\n",
    "            {\n",
    "                'metric_name': metric['name'],\n",
    "                'success': metric['success'].tolist(),\n",
    "                'dist': metric['dist'].tolist(),\n",
    "                'L2_dist': metric['L2_dist'].tolist(),\n",
    "            }\n",
    "        )\n",
    "    json.dump(metrics_to_json, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
