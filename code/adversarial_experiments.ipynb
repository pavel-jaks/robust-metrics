{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv(model, benign_examples, target_labels, metric: Metric, c):\n",
    "    step_size = 1e-2\n",
    "    adversarial_examples = torch.zeros(benign_examples.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    for _ in range(100):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad is not None:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        loss = c * metric(adversarial_examples, benign_examples).sum() \\\n",
    "            + loss_fn(model(adversarial_examples), target_labels)\n",
    "        loss.backward()\n",
    "        adversarial_examples = (adversarial_examples - step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)).detach()\n",
    "    return adversarial_examples\n",
    "\n",
    "\n",
    "def lbfgs_batch(model, benign_examples, labels, metric: Metric):\n",
    "    batch = len(benign_examples)\n",
    "    all_adversarial_examples = torch.zeros(batch, 9, 28, 28)\n",
    "    target_labels = torch.tensor([[i for i in range(10) if i != label] for label in labels])\n",
    "    for i in range(9):\n",
    "        print(f'--- {i} ---')\n",
    "        successful_indexes = []\n",
    "        unsuccessful_indexes = [i for i in range(batch)]\n",
    "        c = 100\n",
    "        while unsuccessful_indexes:\n",
    "            still_benign_examples = torch.tensor([benign_examples[j].tolist() for j in unsuccessful_indexes])\n",
    "            still_target_labels = torch.tensor([target_labels[j, i] for j in unsuccessful_indexes])\n",
    "            adversarial_examples = get_adv(model, still_benign_examples, still_target_labels, metric, c)\n",
    "            adversarial_preds = torch.argmax(model(adversarial_examples), dim=1)\n",
    "            indexes_to_delete = []\n",
    "            for j in range(len(adversarial_examples)):\n",
    "                # print(j)\n",
    "                if adversarial_preds[j] != labels[unsuccessful_indexes[j]] or c <= 0.01:\n",
    "                    all_adversarial_examples[unsuccessful_indexes[j], i, :, :] = adversarial_examples[j, :, :, :]\n",
    "                    successful_indexes.append(unsuccessful_indexes[j])\n",
    "                    indexes_to_delete.append(unsuccessful_indexes[j])\n",
    "            for j in indexes_to_delete:\n",
    "                unsuccessful_indexes.remove(j)\n",
    "            c *= 0.1\n",
    "    expanded_examples = benign_examples.expand(batch, 9, 28, 28)\n",
    "    norms = torch.zeros(batch, 9)\n",
    "    for i in range(9):\n",
    "        norms[:, i] = metric(all_adversarial_examples[:, i, :, :].reshape(batch, 1, 28, 28), expanded_examples.reshape(batch, 1, 28, 28))\n",
    "        preds = torch.argmax(model(all_adversarial_examples[:,i,:,:].reshape(batch, 1, 28, 28)), dim=1)\n",
    "        norms[:, i] += torch.tensor([torch.inf if preds[j] == labels[j] else 0 for j in range(batch)])\n",
    "    selected_adversarial_examples = torch.zeros(benign_examples.shape)\n",
    "    indexes = torch.argmin(norms, dim=1)\n",
    "    for i in range(batch):\n",
    "        selected_adversarial_examples[i, 0, :, :] = all_adversarial_examples[i, indexes[i], :, :]\n",
    "    return selected_adversarial_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Linear(1024, 200),\n",
    "            nn.Flatten(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        return self.seq(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
